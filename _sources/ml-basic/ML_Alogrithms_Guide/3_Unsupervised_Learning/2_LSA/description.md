## 算法说明

以下结合具体例子

首先将以下文本变换为矩阵$X$。矩阵$X$的各元素是文本中出现的单词的个数。

- 文本1：坐汽车去公司
- 文本2：坐车去的
- 文本3：在餐厅吃汉堡牛肉饼
- 文本4：在餐厅吃意大利面

|            | 文本1 | 文本2 | 文本3 | 文本4 |
| ---------- | ----- | ----- | ----- | ----- |
| 汽车       | 1     | 0     | 0     | 0     |
| 公司       | 1     | 0     | 0     | 0     |
| 去         | 1     | 1     | 0     | 0     |
| 车         | 0     | 1     | 0     | 0     |
| 餐厅       | 0     | 0     | 1     | 1     |
| 汉堡牛肉饼 | 0     | 0     | 1     | 0     |
| 吃         | 0     | 0     | 1     | 1     |
| 意大利面   | 0     | 0     | 0     | 1     |

上图为矩阵X，对矩阵X分解后得：

$X = UDV^{T}$

$X = \begin{bmatrix} 0.00 & -0.45 & -0.45 & 0.00 \\ 0.00 & -0.45 & -0.45 & 0.00 \\ \vdots & \vdots & \vdots & \vdots \\ -0.32 & 0.00 & 0.00 & -0.71 \end{bmatrix} \times \begin{bmatrix} 2.24 & 0 & 0 & 0 \\ 0 & 1.90 & 0 & 0 \\ 0 & 0 & 1.18 & 0 \\ 0 & 0 & 0 & 1.00 \end{bmatrix} \times \begin{bmatrix} 0.00 & 0.00 & -0.71 & -0.71 \\ -0.85 & -0.53 & 0.00 & 0.00 \\ -0.53 & 0.85 & 0.00 & 0.00 \\ 0.00 & 0.00 & 0.71 & -0.71 \end{bmatrix}$

矩阵解释：

- $U$是包含单词和归纳的特征的变换信息的矩阵
- $D$是包含信息的重要度的矩阵，是一个对角矩阵，其对角元素按信息的重要度从大到小排列。
- $V$是包含归纳的特征和文本的变换信息的矩阵

### 降维

原始数据有4个特征，但我们希望将其降维到2个特征。

从$D$的4个值中选出最重要的2个：建立一个2行2列的对角矩阵。

为了匹配这个$D$，我们相应地删去$U$的第3列和第4列，以及$V^T$的第3列和第4列，将它们分别变形为8行2列和2行4列的矩阵。

$\hat{X} = \hat{U} \hat{D} \hat{V}^{T}$

$\hat{X} = \begin{bmatrix} 0.00 & -0.45 \\ 0.00 & -0.45 \\ \vdots & \vdots \\ -0.32 & 0.00 \end{bmatrix} \times \begin{bmatrix} 2.25 & 0 \\ 0 & 1.90 \end{bmatrix} \times \begin{bmatrix} 0.00 & 0.00 & -0.71 & -0.71 \\ -0.85 & -0.53 & 0.00 & 0.00 \end{bmatrix}$

该矩阵乘积是原矩阵的近似，即使只用了一半的值，还是在一定程度上保留了原来的信息。

当作为降维算法使用时，我们要用到的是在变换为原始特征的形式之前（在乘以$\widehat{V}^T$之前）的$\widehat{U}\widehat {D}$。$\widehat{U}\widehat {D}$是一个8行2列的矩阵，我们可以将其解释为从归纳的特征中选择的2个重要度高的特征。

![2.png](images/2.png)

以下是关于$\widehat{U}\widehat {D}$的具体数值，将两个特征设为A和B。

|            | A    | B    |
| ---------- | ---- | ---- |
| 汽车       | 0.00 | 0.85 |
| 公司       | 0.00 | 0.85 |
| 去         | 0.00 | 1.38 |
| 车         | 0.00 | 0.53 |
| 餐厅       | 1.41 | 0.00 |
| 汉堡牛肉饼 | 0.71 | 0.00 |
| 吃         | 1.41 | 0.00 |
| 意大利面   | 0.71 | 0.00 |

“汽车”和“车”拥有变量B的值，“汉堡牛肉饼”和“意大利面”拥有变量A的值。A和B的特征值显示了各个单词之间的关联性。
